{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa1783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e378b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_test_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train_full = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train_full = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60cf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_labeled, X_pool, y_labeled, y_pool = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    train_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806473cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_indices = list(range(len(y_labeled)))\n",
    "pool_indices = list(range(len(y_pool)))\n",
    "BATCH_SIZE = 50  \n",
    "N_ITERATIONS = 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b74a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_sampling(model, X_pool, n_samples=50):\n",
    "    \n",
    "   \n",
    "    probas = model.predict_proba(X_pool)\n",
    "    \n",
    "    uncertainties = 1 - np.max(probas, axis=1)\n",
    "    \n",
    "    \n",
    "    uncertain_indices = np.argsort(uncertainties)[-n_samples:][::-1]\n",
    "    \n",
    "    return uncertain_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a355570",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_metrics = {\n",
    "    'iteration': [],\n",
    "    'n_labeled': [],\n",
    "    'accuracy': [],\n",
    "    'f1': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988b048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Active Learning: 100%|██████████| 20/20 [00:27<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import vstack\n",
    "\n",
    "for iteration in tqdm(range(N_ITERATIONS), desc=\"      Active Learning\"):\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "    model.fit(X_labeled, y_labeled)\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "   \n",
    "    al_metrics['iteration'].append(iteration)\n",
    "    al_metrics['n_labeled'].append(len(y_labeled))\n",
    "    al_metrics['accuracy'].append(accuracy)\n",
    "    al_metrics['f1'].append(f1)\n",
    "    \n",
    "    \n",
    "    if len(y_pool) < BATCH_SIZE:\n",
    "        print(f\"\\n      Pool exhausted at iteration {iteration}\")\n",
    "        break\n",
    "    \n",
    "    uncertain_indices = uncertainty_sampling(model, X_pool, n_samples=BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    for idx in uncertain_indices:\n",
    "       \n",
    "        if X_labeled is None:\n",
    "            X_labeled = X_pool[idx]\n",
    "            y_labeled = np.array([y_pool[idx]])\n",
    "        else:\n",
    "            X_labeled = vstack([X_labeled, X_pool[idx]])\n",
    "            y_labeled = np.append(y_labeled, y_pool[idx])\n",
    "    \n",
    "    \n",
    "    for idx in sorted(uncertain_indices, reverse=True):\n",
    "        X_pool = vstack([X_pool[:idx], X_pool[idx+1:]])\n",
    "        y_pool = np.delete(y_pool, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e156ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled_random, X_pool_random, y_labeled_random, y_pool_random = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    train_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "random_metrics = {\n",
    "    'iteration': [],\n",
    "    'n_labeled': [],\n",
    "    'accuracy': [],\n",
    "    'f1': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5509a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Random Sampling: 100%|██████████| 20/20 [00:29<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for iteration in tqdm(range(N_ITERATIONS), desc=\"      Random Sampling\"):\n",
    "    \n",
    "    \n",
    "    model_random = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "    model_random.fit(X_labeled_random, y_labeled_random)\n",
    "    \n",
    "  \n",
    "    y_pred_random = model_random.predict(X_test)\n",
    "    accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "    f1_random = f1_score(y_test, y_pred_random, average='weighted')\n",
    "    \n",
    "    # Store\n",
    "    random_metrics['iteration'].append(iteration)\n",
    "    random_metrics['n_labeled'].append(len(y_labeled_random))\n",
    "    random_metrics['accuracy'].append(accuracy_random)\n",
    "    random_metrics['f1'].append(f1_random)\n",
    "    \n",
    "    \n",
    "    if len(y_pool_random) < BATCH_SIZE:\n",
    "        break\n",
    "    \n",
    "    random_indices = np.random.choice(len(y_pool_random), size=BATCH_SIZE, replace=False)\n",
    "    \n",
    "    \n",
    "    for idx in random_indices:\n",
    "        X_labeled_random = vstack([X_labeled_random, X_pool_random[idx]])\n",
    "        y_labeled_random = np.append(y_labeled_random, y_pool_random[idx])\n",
    "    \n",
    "  \n",
    "    for idx in sorted(random_indices, reverse=True):\n",
    "        X_pool_random = vstack([X_pool_random[:idx], X_pool_random[idx+1:]])\n",
    "        y_pool_random = np.delete(y_pool_random, idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6587b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_df = pd.DataFrame(al_metrics)\n",
    "random_df = pd.DataFrame(random_metrics)\n",
    "\n",
    "final_al_acc = al_df['accuracy'].iloc[-1] * 100\n",
    "final_random_acc = random_df['accuracy'].iloc[-1] * 100\n",
    "improvement = final_al_acc - final_random_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b226f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'active_learning': al_df,\n",
    "    'random_sampling': random_df,\n",
    "    'final_model': model,\n",
    "    'improvement': improvement\n",
    "}\n",
    "\n",
    "with open('active_learning_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
